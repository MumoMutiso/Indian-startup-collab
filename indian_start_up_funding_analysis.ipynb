{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indian Start-up Funding Analysis\n",
    "\n",
    "\n",
    "### Project Scenario\n",
    "The Team is trying to venture into the Indian start-up ecosystem. As the data expert of the team, I was tasked to:\n",
    "\n",
    "- Investigate the ecosystem and propose the best course of action.\n",
    "  - Analyze funding received by start-ups in India from 2018 to 2021.\n",
    "  - Separate data for each year of funding will be provided.\n",
    "  - Find the start-upsâ€™ details, the funding amounts received, and the investors' information.\n",
    "\n",
    "### Business Understanding\n",
    "The Indian startup ecosystem has experienced significant growth and investment over the past few years. As a data expert tasked with investigating this ecosystem, our goal is to analyze the funding received by startups in India from 2018 to 2021 and provide insights to guide investment decisions. By examining the details of startups, funding amounts, and investor information, we aim to understand the trends, opportunities, and challenges within the Indian startup landscape.\n",
    "\n",
    "### Objective\n",
    "To analyze funding trends and dynamics within the Indian start-up ecosystem from 2018 to 2021 and propose strategic recommendations for the team's venture.\n",
    "\n",
    "### Hypothesis Testing\n",
    "Null Hypothesis(Ho): There is no siginificate difference in the amount of funding between startups in Bangalore.\n",
    "Alternative Hypothesis(Ha): There is a siginificate difference in the amount of funding between startups in Banaglore.\n",
    "\n",
    "### Business Questions\n",
    "####\n",
    "1.What sectors have shown the highest growth in terms of funding received over the past four years?\n",
    "\n",
    "2.What locations within India have emerged as the primary hubs for startup activity and investment, and what factors contribute to their prominence?\n",
    "\n",
    "3.Are there any notable differences in funding patterns between early-stage startups and more established companies?\n",
    "\n",
    "4.Which sectors recieve the lowest level of funding and which sectors recieve the highest levels of funding in India.\n",
    "\n",
    "5.Which investors have more impact on startups over the years?\n",
    "\n",
    "6.What are the key characteristics of startups that successfully secure funding, and how do they differ from those that struggle to attract investment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ›¬ Imported all packages. Warnings hidden. ðŸ‘»\n"
     ]
    }
   ],
   "source": [
    "from dotenv import dotenv_values \n",
    "import pyodbc \n",
    "import numpy as np\n",
    "import pandas as pd                      \n",
    "import re     \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics as stat \n",
    "import geopandas as gpd\n",
    "import geoplot as gplt\n",
    "import folium\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from folium.plugins import MarkerCluster\n",
    "from scipy.stats import mannwhitneyu\n",
    "from geopy.geocoders import Nominatim    \n",
    "from scipy.stats import ttest_ind    \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ðŸ›¬ Imported all packages.\", \"Warnings hidden. ðŸ‘»\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Data Set\n",
    "The first data was from a database management system, that is MIRCORSOFT SQL SERVER. Connection was made to the database using an Open Database Connectivity standard library, pyodbc. <br>\n",
    "Two tables were read from the databases. That is, <br>\n",
    "Table 1: dbo.LP1_startup_funding2020 <br>\n",
    "Table 2: dbo.LP1_startup_funding2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file into a dictionary\n",
    "environment_variables = dotenv_values('.env')\n",
    "\n",
    "# Get the values for the credentials you set in the '.env' file\n",
    "server = environment_variables.get(\"SERVER\")\n",
    "database = environment_variables.get(\"DATABASE\")\n",
    "username = environment_variables.get(\"USERNAME\")\n",
    "password = environment_variables.get(\"PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a connection string\n",
    "connection_string = f\"Driver={{SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the connect method of the pyodbc library and pass in the connection string.\n",
    "# This will connect to the server and might take a few seconds to be complete. \n",
    "# Check your internet connection if it takes more time than necessary\n",
    "connection = pyodbc.connect(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the sql query to get the data is what what you see below.\n",
    "# Note that you will not have permissions to insert delete or update this database table.\n",
    "query = \"Select * from dbo.LP1_startup_funding2020\"\n",
    "table_1 = pd.read_sql(query, connection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Select * from dbo.LP1_startup_funding2021\"\n",
    "table_2 = pd.read_sql(query, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1055 entries, 0 to 1054\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Company_Brand  1055 non-null   object \n",
      " 1   Founded        842 non-null    float64\n",
      " 2   HeadQuarter    961 non-null    object \n",
      " 3   Sector         1042 non-null   object \n",
      " 4   What_it_does   1055 non-null   object \n",
      " 5   Founders       1043 non-null   object \n",
      " 6   Investor       1017 non-null   object \n",
      " 7   Amount         801 non-null    float64\n",
      " 8   Stage          591 non-null    object \n",
      " 9   column10       2 non-null      object \n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 82.6+ KB\n"
     ]
    }
   ],
   "source": [
    "table_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1209 entries, 0 to 1208\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Company_Brand  1209 non-null   object \n",
      " 1   Founded        1208 non-null   float64\n",
      " 2   HeadQuarter    1208 non-null   object \n",
      " 3   Sector         1209 non-null   object \n",
      " 4   What_it_does   1209 non-null   object \n",
      " 5   Founders       1205 non-null   object \n",
      " 6   Investor       1147 non-null   object \n",
      " 7   Amount         1206 non-null   object \n",
      " 8   Stage          781 non-null    object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 85.1+ KB\n"
     ]
    }
   ],
   "source": [
    "table_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Brand</th>\n",
       "      <th>Founded</th>\n",
       "      <th>HeadQuarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>What_it_does</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Stage</th>\n",
       "      <th>column10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aqgromalin</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>AgriTech</td>\n",
       "      <td>Cultivating Ideas for Profit</td>\n",
       "      <td>Prasanna Manogaran, Bharani C L</td>\n",
       "      <td>Angel investors</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Krayonnz</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>An academy-guardian-scholar centric ecosystem ...</td>\n",
       "      <td>Saurabh Dixit, Gurudutt Upadhyay</td>\n",
       "      <td>GSF Accelerator</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Pre-seed</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PadCare Labs</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Hygiene management</td>\n",
       "      <td>Converting bio-hazardous waste to harmless waste</td>\n",
       "      <td>Ajinkya Dhariya</td>\n",
       "      <td>Venture Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-seed</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company_Brand  Founded HeadQuarter              Sector  \\\n",
       "0    Aqgromalin   2019.0     Chennai            AgriTech   \n",
       "1      Krayonnz   2019.0   Bangalore              EdTech   \n",
       "2  PadCare Labs   2018.0        Pune  Hygiene management   \n",
       "\n",
       "                                        What_it_does  \\\n",
       "0                       Cultivating Ideas for Profit   \n",
       "1  An academy-guardian-scholar centric ecosystem ...   \n",
       "2   Converting bio-hazardous waste to harmless waste   \n",
       "\n",
       "                           Founders         Investor    Amount     Stage  \\\n",
       "0   Prasanna Manogaran, Bharani C L  Angel investors  200000.0      None   \n",
       "1  Saurabh Dixit, Gurudutt Upadhyay  GSF Accelerator  100000.0  Pre-seed   \n",
       "2                   Ajinkya Dhariya   Venture Center       NaN  Pre-seed   \n",
       "\n",
       "  column10  \n",
       "0     None  \n",
       "1     None  \n",
       "2     None  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Brand</th>\n",
       "      <th>Founded</th>\n",
       "      <th>HeadQuarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>What_it_does</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Stage</th>\n",
       "      <th>column10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>Walrus</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Fintech</td>\n",
       "      <td>It provides banking solutions for teens and yo...</td>\n",
       "      <td>Bhagaban Behera, Sriharsha Shetty, Nakul Kelkar</td>\n",
       "      <td>Better Capital</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-Seed</td>\n",
       "      <td>Pre-Seed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>goDutch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Fintech</td>\n",
       "      <td>Group Payments platform</td>\n",
       "      <td>Aniruddh Singh, Riyaz Khan, Sagar Sheth</td>\n",
       "      <td>Matrix India, Y Combinator, Global Founders Ca...</td>\n",
       "      <td>1700000.0</td>\n",
       "      <td>Seed Round</td>\n",
       "      <td>Seed Round</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Brand  Founded HeadQuarter   Sector  \\\n",
       "611        Walrus   2019.0   Bangalore  Fintech   \n",
       "613       goDutch      NaN      Mumbai  Fintech   \n",
       "\n",
       "                                          What_it_does  \\\n",
       "611  It provides banking solutions for teens and yo...   \n",
       "613                            Group Payments platform   \n",
       "\n",
       "                                            Founders  \\\n",
       "611  Bhagaban Behera, Sriharsha Shetty, Nakul Kelkar   \n",
       "613          Aniruddh Singh, Riyaz Khan, Sagar Sheth   \n",
       "\n",
       "                                              Investor     Amount       Stage  \\\n",
       "611                                     Better Capital        NaN    Pre-Seed   \n",
       "613  Matrix India, Y Combinator, Global Founders Ca...  1700000.0  Seed Round   \n",
       "\n",
       "       column10  \n",
       "611    Pre-Seed  \n",
       "613  Seed Round  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_1[table_1['column10'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop column10 in table_1 since it has just two values that are not null and are also just repetition of values in Stage column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Brand</th>\n",
       "      <th>Founded</th>\n",
       "      <th>HeadQuarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>What_it_does</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aqgromalin</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>AgriTech</td>\n",
       "      <td>Cultivating Ideas for Profit</td>\n",
       "      <td>Prasanna Manogaran, Bharani C L</td>\n",
       "      <td>Angel investors</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Krayonnz</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>An academy-guardian-scholar centric ecosystem ...</td>\n",
       "      <td>Saurabh Dixit, Gurudutt Upadhyay</td>\n",
       "      <td>GSF Accelerator</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Pre-seed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PadCare Labs</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Hygiene management</td>\n",
       "      <td>Converting bio-hazardous waste to harmless waste</td>\n",
       "      <td>Ajinkya Dhariya</td>\n",
       "      <td>Venture Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-seed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company_Brand  Founded HeadQuarter              Sector  \\\n",
       "0    Aqgromalin   2019.0     Chennai            AgriTech   \n",
       "1      Krayonnz   2019.0   Bangalore              EdTech   \n",
       "2  PadCare Labs   2018.0        Pune  Hygiene management   \n",
       "\n",
       "                                        What_it_does  \\\n",
       "0                       Cultivating Ideas for Profit   \n",
       "1  An academy-guardian-scholar centric ecosystem ...   \n",
       "2   Converting bio-hazardous waste to harmless waste   \n",
       "\n",
       "                           Founders         Investor    Amount     Stage  \n",
       "0   Prasanna Manogaran, Bharani C L  Angel investors  200000.0      None  \n",
       "1  Saurabh Dixit, Gurudutt Upadhyay  GSF Accelerator  100000.0  Pre-seed  \n",
       "2                   Ajinkya Dhariya   Venture Center       NaN  Pre-seed  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop column10\n",
    "table_1.drop('column10', axis=1, inplace=True) if 'column10' in table_1.columns else table_1\n",
    "table_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the column names\n",
    "\n",
    "def stripper(string: str, strip: list) -> str:\n",
    "    \"\"\"Strips a strip list from a given string and returns the string\"\"\"\n",
    "    for s in strip:\n",
    "        string = string.replace(s, '')\n",
    "        \n",
    "    return string\n",
    "    \n",
    "def replacer(string: str, replace: list) -> str:\n",
    "    \"\"\"Replaces each character in replace list with underscore given a string and returns the string\"\"\"\n",
    "    for r in replace:\n",
    "        string = string.replace(r, '_')\n",
    "                \n",
    "    return string\n",
    "    \n",
    "def clean_column_names(df):\n",
    "    strip   = ['(', ')', '$']\n",
    "    replace = [' ', '/'] \n",
    "    df.columns = [replacer(stripper(col_name.lower(), strip), replace) for col_name in df.columns]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the column names\n",
    "table_1 = clean_column_names(table_1)\n",
    "table_2 = clean_column_names(table_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1055 entries, 0 to 1054\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   company_brand  1055 non-null   object \n",
      " 1   founded        842 non-null    float64\n",
      " 2   headquarter    961 non-null    object \n",
      " 3   sector         1042 non-null   object \n",
      " 4   what_it_does   1055 non-null   object \n",
      " 5   founders       1043 non-null   object \n",
      " 6   investor       1017 non-null   object \n",
      " 7   amount         801 non-null    float64\n",
      " 8   stage          591 non-null    object \n",
      "dtypes: float64(2), object(7)\n",
      "memory usage: 74.3+ KB\n"
     ]
    }
   ],
   "source": [
    "table_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1209 entries, 0 to 1208\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   company_brand  1209 non-null   object \n",
      " 1   founded        1208 non-null   float64\n",
      " 2   headquarter    1208 non-null   object \n",
      " 3   sector         1209 non-null   object \n",
      " 4   what_it_does   1209 non-null   object \n",
      " 5   founders       1205 non-null   object \n",
      " 6   investor       1147 non-null   object \n",
      " 7   amount         1206 non-null   object \n",
      " 8   stage          781 non-null    object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 85.1+ KB\n"
     ]
    }
   ],
   "source": [
    "table_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create year column to identify each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1: dbo.LP1_startup_funding2020\n",
    "table_1['year'] = 2020\n",
    "\n",
    "# Table 2: dbo.LP1_startup_funding2021\n",
    "table_2['year'] = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Data Set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2264 entries, 0 to 2263\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   company_brand  2264 non-null   object \n",
      " 1   founded        2050 non-null   float64\n",
      " 2   headquarter    2169 non-null   object \n",
      " 3   sector         2251 non-null   object \n",
      " 4   what_it_does   2264 non-null   object \n",
      " 5   founders       2248 non-null   object \n",
      " 6   investor       2164 non-null   object \n",
      " 7   amount         2007 non-null   object \n",
      " 8   stage          1372 non-null   object \n",
      " 9   year           2264 non-null   int64  \n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 177.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# First Data set\n",
    "first_dataset = pd.concat([table_1, table_2], ignore_index=True)\n",
    "\n",
    "first_dataset.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([200000.0, 100000.0, nan, 400000.0, 340000.0, 600000.0, 45000000.0,\n",
       "       1000000.0, 2000000.0, 1200000.0, 660000000.0, 120000.0, 7500000.0,\n",
       "       5000000.0, 500000.0, 3000000.0, 10000000.0, 145000000.0,\n",
       "       100000000.0, 21000000.0, 4000000.0, 20000000.0, 560000.0, 275000.0,\n",
       "       4500000.0, 15000000.0, 390000000.0, 7000000.0, 5100000.0,\n",
       "       700000000.0, 2300000.0, 700000.0, 19000000.0, 9000000.0,\n",
       "       40000000.0, 750000.0, 1500000.0, 7800000.0, 50000000.0, 80000000.0,\n",
       "       30000000.0, 1700000.0, 2500000.0, 40000.0, 33000000.0, 35000000.0,\n",
       "       300000.0, 25000000.0, 3500000.0, 200000000.0, 6000000.0, 1300000.0,\n",
       "       4100000.0, 575000.0, 800000.0, 28000000.0, 18000000.0, 3200000.0,\n",
       "       900000.0, 250000.0, 4700000.0, 75000000.0, 8000000.0, 121000000.0,\n",
       "       55000000.0, 3300000.0, 11000000.0, 16000000.0, 5400000.0,\n",
       "       150000000.0, 4200000.0, 22000000.0, 52000000.0, 1100000.0,\n",
       "       118000000.0, 1600000.0, 18500000.0, 70000000000.0, 800000000.0,\n",
       "       400000000.0, 150000.0, 176000000.0, 60000000.0, 470000.0, 240000.0,\n",
       "       3000000000.0, 74000000.0, 62000000.0, 2100000.0, 500000000.0,\n",
       "       12500000.0, 2200000000.0, 5060000.0, 225000000.0, 24700000.0,\n",
       "       7700000.0, 19067328.0, 51000000.0, 115000.0, 54000.0, 20000.0,\n",
       "       803146.0, 238000.0, 10220000.0, 1020000.0, 12000000.0, 13400000.0,\n",
       "       170000000.0, 2900000.0, 543000.0, 90000000.0, 3400000.0,\n",
       "       23000000.0, 8090000.0, 1030000.0, 5040000.0, 360000.0, 1400000.0,\n",
       "       650000.0, 54000000.0, 42500000.0, 11370000.0, 325000.0, 410000.0,\n",
       "       450000.0, 682000.0, 4050000.0, 1050000.0, 1080000.0, 4300000.0,\n",
       "       6800000.0, 2110000.0, 764000.0, 603000.0, 409000.0, 292000.0,\n",
       "       286000.0, 136000.0, 546000.0, 887000.0, 43000.0, 40900.0,\n",
       "       2200000.0, 5660000.0, 350000.0, 110000.0, 122000000.0, 11635000.0,\n",
       "       2800000.0, 1065000.0, 669000.0, 16076000.0, 649600.0, 6700000.0,\n",
       "       220000.0, 266500.0, 2879000.0, 26500000.0, 351000.0, 46761000.0,\n",
       "       175000.0, 11241000.0, 804000.0, 1340000.0, 467000.0, 133000.0,\n",
       "       3823000.0, 934000.0, 293000.0, 198000.0, 927000.0, 971000.0,\n",
       "       3060000.0, 1862000.0, 232000.0, 2888000.0, 1328000.0, 15500000.0,\n",
       "       56000000.0, 2250000.0, 16753000.0, 3700000.0, 1470000.0, 530000.0,\n",
       "       267000.0, 3344000.0, 7200000.0, 2743000.0, 6082000.0, 6609000.0,\n",
       "       27700000.0, 5940000.0, 3964000.0, 5500000.0, 197000.0, 4327000.0,\n",
       "       459000.0, 3937000.0, 1313500.0, 229800.0, 5305000.0, 264000.0,\n",
       "       1750000.0, 5967000.0, 2980000.0, 323000.0, 1326000.0, 27000000.0,\n",
       "       5200000.0, 2530000.0, 792000.0, 11363000.0, 1715000.0, 329000.0,\n",
       "       5271000.0, 8700000.0, 3226000.0, 5900000.0, 44000000.0, 3879000.0,\n",
       "       13000000.0, 8800000.0, 9500000.0, 920000.0, 35600000.0, 9400000.0,\n",
       "       790000.0, 480000.0, 160000.0, 8200000.0, 4257000.0, 1410000.0,\n",
       "       349800.0, 786000.0, 2004000.0, 123000000.0, 248000.0, 24000000.0,\n",
       "       14259000.0, 24500000.0, 3800000.0, 18370000.0, 68525000.0,\n",
       "       4800000.0, 1834000.0, 23850000.0, 43000000.0, 21600000.0,\n",
       "       4598000.0, 13137000.0, 115000000.0, 3900000.0, 670000.0, 8500000.0,\n",
       "       3148000.0, 2600000.0, 4049500.0, 10500000.0, 6500000.0, 43700000.0,\n",
       "       13800000.0, 306900.0, 420000.0, 627300.0, 113000000.0, 32000000.0,\n",
       "       110000000.0, 1397000.0, 448500.0, 7975700.0, 330000.0, 5600000.0,\n",
       "       1402000.0, 21500000.0, 296000000.0, 4900000.0, 1402400.0,\n",
       "       12618300.0, 9900000.0, 982530.0, 70185200.0, 210000000.0,\n",
       "       84000000.0, 39000000.0, 2700000.0, 1403400.0, 105000000.0,\n",
       "       103000000.0, 281300.0, 12700.0, 25000.0, 97500000.0, 507000.0,\n",
       "       8400000.0, 18300000.0, 125000000.0, 181000.0, 280000.0, 14700000.0,\n",
       "       13200000.0, 8043000.0, '$1,200,000', '$120,000,000', '$30,000,000',\n",
       "       '$51,000,000', '$2,000,000', '$188,000,000', '$200,000',\n",
       "       'Undisclosed', '$1,000,000', '$3,000,000', '$100,000', '$700,000',\n",
       "       '$9,000,000', '$40,000,000', '$49,000,000', '$400,000', '$300,000',\n",
       "       '$25,000,000', '$160,000,000', '$150,000', '$1,800,000',\n",
       "       '$5,000,000', '$850,000', '$53,000,000', '$500,000', '$1,100,000',\n",
       "       '$6,000,000', '$800,000', '$10,000,000', '$21,000,000',\n",
       "       '$7,500,000', '$26,000,000', '$7,400,000', '$1,500,000',\n",
       "       '$600,000', '$800,000,000', '$17,000,000', '$3,500,000',\n",
       "       '$15,000,000', '$215,000,000', '$2,500,000', '$350,000,000',\n",
       "       '$5,500,000', '$83,000,000', '$110,000,000', '$500,000,000',\n",
       "       '$65,000,000', '$150,000,000,000', '$300,000,000', '$2,200,000',\n",
       "       '$35,000,000', '$140,000,000', '$4,000,000', '$13,000,000', None,\n",
       "       '$Undisclosed', '$2000000', '$800000', '$6000000', '$2500000',\n",
       "       '$9500000', '$13000000', '$5000000', '$8000000', '$1000000',\n",
       "       'Upsparks', '$200000', '$12000000', '$1500000', '$1700000',\n",
       "       '$5500000', '$400000', '$150000000', '$4000000', '$100000000',\n",
       "       '$500000', '$15000000', '$10000000', '$40000000', '$225000000',\n",
       "       '$6700000', '$1300000', '$20000000', '$250000', '$21000000',\n",
       "       '$1200000', '$52000000', '$3800000', '$17500000', '$42000000',\n",
       "       '$2300000', '$7000000', '$30000000', '$450000000', '$28000000',\n",
       "       '$300000', '$3500000', '$8500000', '$25000000', '$3000000',\n",
       "       '$37000000', '$370000000', '$700000', '$16000000', '$100000',\n",
       "       '$44000000', '$770000', '$125000000', '$35000000', '$50000000',\n",
       "       '$4900000', '$145000000', '$22000000', '$70000000', '$6600000',\n",
       "       '$32000000', '$24000000', '$725000', '$461000', 'Series C', 'Seed',\n",
       "       '$96000000', '$60000000', '$500000000', '$266000000', '$4500000',\n",
       "       '$325000000', '$6500000', '$1600000', '$150000', '$225000',\n",
       "       '$85000000', '$235000', '$260000', '$2900000', '$53000000',\n",
       "       '$1100000', '$86000000', '$130000', '$$100,00', '$111000000',\n",
       "       '$265000', '$76000000', '$100,000,000', '$75,000,000',\n",
       "       '$3,800,000', '$12,000,000', '$1,600,000', '$260,000',\n",
       "       '$1,000,000,000', '$18,000,000', '$20,000,000', '$350,000',\n",
       "       '$95,000,000', '$4,100,000', '$5,200,000', '$8,000,000',\n",
       "       '$1,400,000', '$2,600,000', '$900,000', '$250,000', '$16,000,000',\n",
       "       '$7,000,000', '$11,000,000', '$280,000,000', '$50,000,000',\n",
       "       '$14,300,000', '$81,000,000', '$1,300,000', '$8,200,000',\n",
       "       '$70,000,000', '$720,000', '$600000', '$9000000', '$1800000',\n",
       "       '$330000', '$undisclosed', '$200000000', '$36000000', '$67000000',\n",
       "       '$10200000', '$220000000', '$108000000', '$75000000', '$450000',\n",
       "       '$660000000', 'ah! Ventures', '$45000000', '$3200000', '$370000',\n",
       "       'Pre-series A', 'ITO Angel Network, LetsVenture', '$48000000',\n",
       "       '$3600000', '$11000000', '$192000000', '$65000000', '$1400000',\n",
       "       '$1900000', '$41000000', '$144000000', '$5200000', '$270000000',\n",
       "       '$140000', '$250000000', '$320000', '$350000000', '$4800000',\n",
       "       '$38000000', '$125000', '$26000000', '$64000000', '$620000',\n",
       "       '$900000', 'JITO Angel Network, LetsVenture', '$2600000',\n",
       "       '$1,250,000', '$400,000,000', '$1,700,000', '$27,000,000',\n",
       "       '$234,000,000', '$460,000,000', '$13,500,000', '$5,100,000',\n",
       "       '$195,000,000', '$125,000', '$45,000,000', '$200,000,000',\n",
       "       '$7,300,000', '$6,300,000', '$12,500,000', '$24,000,000',\n",
       "       '$140,000', '$16,500,000', '$340,000', '$43,000,000',\n",
       "       '$150,000,000', '$3300000', '$92000000', '$17000000', '$135000000',\n",
       "       '$$1,55,000', '$2100000', '$840000000', '$248000000', '$4300000',\n",
       "       '$570000', '$2200000', '$4700000', '$300000000', '$260000000',\n",
       "       '$140000000', '$175000000', '$19000000', '$810000', '$7500000',\n",
       "       '$600000000', '$90000000', '$5700000', '$6750000', '$78000000',\n",
       "       '$5400000', '$115000000', '$255000000', '$18000000', '$570000000',\n",
       "       '$550000', '$2700000', '$4200000', '$31000000', '$540000',\n",
       "       '$14000000', '$340000', '$', '$6200000', '$750000', '$6300000',\n",
       "       '$23000000', '$55000000'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_dataset['amount'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 89 entries, 0 to 88\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   company_brand  89 non-null     object \n",
      " 1   founded        60 non-null     float64\n",
      " 2   headquarter    70 non-null     object \n",
      " 3   sector         84 non-null     object \n",
      " 4   what_it_does   89 non-null     object \n",
      " 5   founders       86 non-null     object \n",
      " 6   investor       89 non-null     object \n",
      " 7   amount         89 non-null     object \n",
      " 8   stage          43 non-null     object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 6.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "second_dataset = pd.read_csv('datasets/individual_csv/startup_funding2019.csv')\n",
    "\n",
    "second_dataset = clean_column_names(second_dataset)\n",
    "\n",
    "second_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['$6,300,000', '$150,000,000', '$28,000,000', '$30,000,000',\n",
       "       '$6,000,000', 'Undisclosed', '$1,000,000', '$20,000,000',\n",
       "       '$275,000,000', '$22,000,000', '$5,000,000', '$140,500',\n",
       "       '$540,000,000', '$15,000,000', '$182,700', '$12,000,000',\n",
       "       '$11,000,000', '$15,500,000', '$1,500,000', '$5,500,000',\n",
       "       '$2,500,000', '$140,000', '$230,000,000', '$49,400,000',\n",
       "       '$32,000,000', '$26,000,000', '$150,000', '$400,000', '$2,000,000',\n",
       "       '$100,000,000', '$8,000,000', '$100,000', '$50,000,000',\n",
       "       '$120,000,000', '$4,000,000', '$6,800,000', '$36,000,000',\n",
       "       '$5,700,000', '$25,000,000', '$600,000', '$70,000,000',\n",
       "       '$60,000,000', '$220,000', '$2,800,000', '$2,100,000',\n",
       "       '$7,000,000', '$311,000,000', '$4,800,000', '$693,000,000',\n",
       "       '$33,000,000'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_dataset['amount'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 526 entries, 0 to 525\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   company_name   526 non-null    object\n",
      " 1   industry       526 non-null    object\n",
      " 2   round_series   526 non-null    object\n",
      " 3   amount         526 non-null    object\n",
      " 4   location       526 non-null    object\n",
      " 5   about_company  526 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 24.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "third_dataset = pd.read_csv('datasets/individual_csv/startup_funding2018.csv')\n",
    "\n",
    "third_dataset = clean_column_names(third_dataset)\n",
    "\n",
    "third_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['250000', 'â‚¹40,000,000', 'â‚¹65,000,000', '2000000', 'â€”', '1600000',\n",
       "       'â‚¹16,000,000', 'â‚¹50,000,000', 'â‚¹100,000,000', '150000', '1100000',\n",
       "       'â‚¹500,000', '6000000', '650000', 'â‚¹35,000,000', 'â‚¹64,000,000',\n",
       "       'â‚¹20,000,000', '1000000', '5000000', '4000000', 'â‚¹30,000,000',\n",
       "       '2800000', '1700000', '1300000', 'â‚¹5,000,000', 'â‚¹12,500,000',\n",
       "       'â‚¹15,000,000', '500000', 'â‚¹104,000,000', 'â‚¹45,000,000', '13400000',\n",
       "       'â‚¹25,000,000', 'â‚¹26,400,000', 'â‚¹8,000,000', 'â‚¹60,000', '9000000',\n",
       "       '100000', '20000', '120000', 'â‚¹34,000,000', 'â‚¹342,000,000',\n",
       "       '$143,145', 'â‚¹600,000,000', '$742,000,000', 'â‚¹1,000,000,000',\n",
       "       'â‚¹2,000,000,000', '$3,980,000', '$10,000', 'â‚¹100,000',\n",
       "       'â‚¹250,000,000', '$1,000,000,000', '$7,000,000', '$35,000,000',\n",
       "       'â‚¹550,000,000', '$28,500,000', '$2,000,000', 'â‚¹240,000,000',\n",
       "       'â‚¹120,000,000', '$2,400,000', '$30,000,000', 'â‚¹2,500,000,000',\n",
       "       '$23,000,000', '$150,000', '$11,000,000', 'â‚¹44,000,000',\n",
       "       '$3,240,000', 'â‚¹60,000,000', '$540,000,000', 'â‚¹650,000,000',\n",
       "       'â‚¹1,600,000,000', '$900,000', '$10,000,000', '$1,500,000',\n",
       "       'â‚¹70,000,000', '$1,000,000', '$5,000,000', '$14,000,000',\n",
       "       'â‚¹102,500,000', '$100,000,000', 'â‚¹1,200,000', 'â‚¹5,200,000,000',\n",
       "       '$800,000', '$1,041,000', '$100,000', '$15,000', '1400000',\n",
       "       '1200000', '2200000', '1800000', '3600000', 'â‚¹9,500,000', '300000',\n",
       "       '6830000', '200000', 'â‚¹150,000,000', '4300000', '364846', '400000',\n",
       "       '1500000', 'â‚¹7,000,000', 'â‚¹1,400,000', 'â‚¹10,000,000',\n",
       "       'â‚¹22,500,000', '13200000', '50000', 'â‚¹140,200,000', '3000000',\n",
       "       '1250000', '180000', 'â‚¹19,200,000', 'â‚¹103,000,000', '4200000',\n",
       "       '175000', '1450000', 'â‚¹200,000', '4500000', '600000',\n",
       "       'â‚¹16,600,000', 'â‚¹12,000,000', '15000000', 'â‚¹33,000,000', '125000',\n",
       "       '130000', 'â‚¹34,900,000', 'â‚¹72,000,000', '17200000', 'â‚¹32,000,000',\n",
       "       '3500000', 'â‚¹135,000,000', '12000000', '$40,000,000', '$1,100,000',\n",
       "       '$50,000,000', 'â‚¹1,540,000,000', '$3,000,000', '$6,000,000',\n",
       "       'â‚¹140,000,000', '$41,900,000', 'â‚¹1,410,000,000', '$3,530,000',\n",
       "       '$200,000', '$3,300,000', 'â‚¹580,000,000', 'â‚¹36,000,000',\n",
       "       'â‚¹340,000,000', '$210,000,000', '$37,680,000', '$250,000',\n",
       "       '$20,000', 'â‚¹510,000,000', 'â‚¹2,200,000,000', '22000000', '70000',\n",
       "       '10000000', 'â‚¹15,392,000,000', 'â‚¹20,000,000,000', 'â‚¹4,000,000,000',\n",
       "       '185000000', '65000000', 'â‚¹165,000,000', '700000', '30000000',\n",
       "       'â‚¹210,000,000', '210000000', 'â‚¹2,029,600,000', '75000000',\n",
       "       'â‚¹80,000,000', '1760000', '2700000', 'â‚¹280,000,000',\n",
       "       'â‚¹800,000,000', '750000', '2500000', '80000000', '25000000',\n",
       "       'â‚¹730,000,000', 'â‚¹400,000,000', '3700000', '5600000',\n",
       "       'â‚¹260,000,000', '99230000', '70000000', '40000', '550000',\n",
       "       '50000000', '365000000', 'â‚¹8,750,000', 'â‚¹78,000,000', '28000000',\n",
       "       'â‚¹264,000,000', '100000000', 'â‚¹1,130,000,000', 'â‚¹810,000,000',\n",
       "       'â‚¹1,400,000,000', '14900000', '225000000', '7500', '35000000'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_dataset['amount'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix location values, take every letter before the first comma as headquarter\n",
    "third_dataset['location'] = [location.split(',')[0] for location in third_dataset['location']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 526 entries, 0 to 525\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   company_brand  526 non-null    object\n",
      " 1   sector         526 non-null    object\n",
      " 2   stage          526 non-null    object\n",
      " 3   amount         526 non-null    object\n",
      " 4   headquarter    526 non-null    object\n",
      " 5   what_it_does   526 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 24.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Rename round_series to stage and location to headquarter\n",
    "third_dataset.rename(columns={\n",
    "    'company_name': 'company_brand', \n",
    "    'industry': 'sector', \n",
    "    'round_series': 'stage', \n",
    "    'about_company': 'what_it_does', \n",
    "    'location': 'headquarter'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "third_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Year column to identify each dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create year column\n",
    "\n",
    "# The second data is a flat-file name startup_funding2019.csv\n",
    "second_dataset['year'] = 2019\n",
    "\n",
    "# The third part of the data flat-file named startup_funding2018.csv\n",
    "third_dataset['year']  = 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the final concatenated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2879 entries, 0 to 2878\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   company_brand  2879 non-null   object \n",
      " 1   founded        2110 non-null   float64\n",
      " 2   headquarter    2765 non-null   object \n",
      " 3   sector         2861 non-null   object \n",
      " 4   what_it_does   2879 non-null   object \n",
      " 5   founders       2334 non-null   object \n",
      " 6   investor       2253 non-null   object \n",
      " 7   amount         2622 non-null   object \n",
      " 8   stage          1941 non-null   object \n",
      " 9   year           2879 non-null   int64  \n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 225.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Final Data set\n",
    "final_dataset = pd.concat([first_dataset, second_dataset, third_dataset], ignore_index=True)\n",
    "\n",
    "final_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_brand</th>\n",
       "      <th>founded</th>\n",
       "      <th>headquarter</th>\n",
       "      <th>sector</th>\n",
       "      <th>what_it_does</th>\n",
       "      <th>founders</th>\n",
       "      <th>investor</th>\n",
       "      <th>amount</th>\n",
       "      <th>stage</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aqgromalin</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>AgriTech</td>\n",
       "      <td>Cultivating Ideas for Profit</td>\n",
       "      <td>Prasanna Manogaran, Bharani C L</td>\n",
       "      <td>Angel investors</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Krayonnz</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>An academy-guardian-scholar centric ecosystem ...</td>\n",
       "      <td>Saurabh Dixit, Gurudutt Upadhyay</td>\n",
       "      <td>GSF Accelerator</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Pre-seed</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PadCare Labs</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Hygiene management</td>\n",
       "      <td>Converting bio-hazardous waste to harmless waste</td>\n",
       "      <td>Ajinkya Dhariya</td>\n",
       "      <td>Venture Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-seed</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCOME</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Escrow</td>\n",
       "      <td>Escrow-as-a-service platform</td>\n",
       "      <td>Ritesh Tiwari</td>\n",
       "      <td>Venture Catalysts, PointOne Capital</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gramophone</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Indore</td>\n",
       "      <td>AgriTech</td>\n",
       "      <td>Gramophone is an AgTech platform enabling acce...</td>\n",
       "      <td>Ashish Rajan Singh, Harshit Gupta, Nishant Mah...</td>\n",
       "      <td>Siana Capital Management, Info Edge</td>\n",
       "      <td>340000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_brand  founded headquarter              sector  \\\n",
       "0    Aqgromalin   2019.0     Chennai            AgriTech   \n",
       "1      Krayonnz   2019.0   Bangalore              EdTech   \n",
       "2  PadCare Labs   2018.0        Pune  Hygiene management   \n",
       "3         NCOME   2020.0   New Delhi              Escrow   \n",
       "4    Gramophone   2016.0      Indore            AgriTech   \n",
       "\n",
       "                                        what_it_does  \\\n",
       "0                       Cultivating Ideas for Profit   \n",
       "1  An academy-guardian-scholar centric ecosystem ...   \n",
       "2   Converting bio-hazardous waste to harmless waste   \n",
       "3                       Escrow-as-a-service platform   \n",
       "4  Gramophone is an AgTech platform enabling acce...   \n",
       "\n",
       "                                            founders  \\\n",
       "0                    Prasanna Manogaran, Bharani C L   \n",
       "1                   Saurabh Dixit, Gurudutt Upadhyay   \n",
       "2                                    Ajinkya Dhariya   \n",
       "3                                      Ritesh Tiwari   \n",
       "4  Ashish Rajan Singh, Harshit Gupta, Nishant Mah...   \n",
       "\n",
       "                              investor    amount     stage  year  \n",
       "0                      Angel investors  200000.0      None  2020  \n",
       "1                      GSF Accelerator  100000.0  Pre-seed  2020  \n",
       "2                       Venture Center       NaN  Pre-seed  2020  \n",
       "3  Venture Catalysts, PointOne Capital  400000.0      None  2020  \n",
       "4  Siana Capital Management, Info Edge  340000.0      None  2020  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Headquarter & Sector column\n",
    "    - If column value contains '#REF!', clean it and shift the row starting from that column by 1 step and until the stage column\n",
    "    - Sanitize sector column if after cleaning and shifting, but the sector value is also present among unique values of the headquarter column\n",
    "    - Fixes index 1297, 1312, 2155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove '#REF!' in a series\n",
    "def remove_ref(value):\n",
    "    if isinstance(value, str):\n",
    "        value = value.replace('#REF!', '').strip()\n",
    "            \n",
    "    return value\n",
    "\n",
    "# Columns of Interest \n",
    "columns = ['headquarter', 'investor']\n",
    "for column in columns:    \n",
    "    # Identify rows where column value contains '#REF!\n",
    "    mask = final_dataset[column].str.contains('#REF!')\n",
    "    \n",
    "    # Fill missing values in mask with False\n",
    "    mask.fillna(False, inplace=True)\n",
    "    \n",
    "    # Update the column by applying the remove_ref function to the column\n",
    "    final_dataset.loc[mask, column] = final_dataset.loc[mask, column].apply(remove_ref)\n",
    "    \n",
    "    # Shift values in selected rows excluding the last column 'year'\n",
    "    final_dataset.loc[mask, column:'stage'] = final_dataset.loc[mask, column:'stage'].shift(1, axis=1)\n",
    "\n",
    "\n",
    "# Sanitisizing the sector column after shifting\n",
    "mask = final_dataset['sector'].apply(lambda x: x in final_dataset['headquarter'].unique())\n",
    "\n",
    "# Update 'headquarter' value with 'sector' value\n",
    "final_dataset.loc[mask, 'headquarter'] = final_dataset.loc[mask, 'sector']\n",
    "\n",
    "# Set the 'sector' value to NaN\n",
    "final_dataset.loc[mask, 'sector'] = np.nan          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace 'None' string values with NaN element-wise allowing for consistent representation of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function replace None with NaN\n",
    "def replace_none(value):\n",
    "    if isinstance(value, str) and (value.lower() == 'none' or value.lower() == 'nan'):\n",
    "        value = np.nan\n",
    "    \n",
    "    return value\n",
    "\n",
    "# Apply the function to all columns\n",
    "final_dataset = final_dataset.applymap(replace_none) # element-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2879 entries, 0 to 2878\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   company_brand  2879 non-null   object \n",
      " 1   founded        2110 non-null   float64\n",
      " 2   headquarter    2751 non-null   object \n",
      " 3   sector         2781 non-null   object \n",
      " 4   what_it_does   2879 non-null   object \n",
      " 5   founders       2334 non-null   object \n",
      " 6   investor       2252 non-null   object \n",
      " 7   amount         2623 non-null   object \n",
      " 8   stage          1945 non-null   object \n",
      " 9   year           2879 non-null   int64  \n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 225.1+ KB\n"
     ]
    }
   ],
   "source": [
    "final_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If a value in stage column is a website link, its correct value is NaN\n",
    "\n",
    "**Website link in stage column is https://docs.google.com/spreadsheets/d/1x9ziNeaz6auNChIHnMI8U6kS7knTr3byy_YBGfQaoUA/edit#gid=1861303593**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove website link from stage column\n",
    "def remove_website_link(value):\n",
    "    # Regular expression pattern to match website URLs that begin with http:// or https:// with an optional www\n",
    "    pattern = r'https?://(?:www\\.)?\\w+\\.\\w+(?:/\\S*)?'\n",
    "    \n",
    "    # Check if the value is a string and matches the pattern\n",
    "    if isinstance(value, str) and re.match(pattern, value):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove website link values from the stage column\n",
    "final_dataset['stage'] = final_dataset['stage'].apply(remove_website_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exchange rates \n",
    "\n",
    "[Source: OFX](https://www.ofx.com/en-au/forex-news/historical-exchange-rates/yearly-average-rates/)\n",
    "```bash\n",
    "exchange_rates = {\n",
    "    2018: 0.014649,\n",
    "    2019: 0.014209,\n",
    "    2020: 0.013501,\n",
    "    2021: 0.013527\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean amount values\n",
    "def floater(string):\n",
    "    try:\n",
    "        string = float(string)\n",
    "    except ValueError:\n",
    "        string = np.nan\n",
    "    \n",
    "    return string\n",
    "    \n",
    "def clean_amount(row): \n",
    "    amount = row[0]    \n",
    "    year   = row['year'] \n",
    "    \n",
    "    # Source: https://www.ofx.com/en-au/forex-news/historical-exchange-rates/yearly-average-rates/\n",
    "    exchange_rates = {\n",
    "        2018: 0.014649,\n",
    "        2019: 0.014209,\n",
    "        2020: 0.013501,\n",
    "        2021: 0.013527\n",
    "    }\n",
    "    \n",
    "    exchange_rate = exchange_rates[year]   \n",
    "    \n",
    "    # Convert to string\n",
    "    amount = str(amount)   \n",
    "    \n",
    "    if isinstance(amount, str):        \n",
    "        # Set of elements to replace\n",
    "        to_replace = {' ', ','}\n",
    "\n",
    "        # Replace each element in the set with an empty string\n",
    "        for r in to_replace:\n",
    "            amount = amount.replace(r, '')        \n",
    "                        \n",
    "        if amount == '' or amount == 'â€”': \n",
    "            amount = np.nan\n",
    "        # If the amount is in INR (Indian Rupees), convert it to USD using the conversion rate of the year\n",
    "        elif 'â‚¹' in amount:\n",
    "            amount = amount.replace('â‚¹', '')\n",
    "            amount = floater(amount) * exchange_rate\n",
    "        \n",
    "        # If the amount is in USD, remove the '$' symbol and convert it to a float\n",
    "        elif '$' in amount:\n",
    "            amount = amount.replace('$', '')\n",
    "            amount = floater(amount)\n",
    "        else:\n",
    "            amount = floater(amount)\n",
    "\n",
    "    \n",
    "    return amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_brand      0\n",
       "founded          769\n",
       "headquarter      128\n",
       "sector            98\n",
       "what_it_does       0\n",
       "founders         545\n",
       "investor         627\n",
       "amount           256\n",
       "stage            935\n",
       "year               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the investor value is a number or contains $, the correct value for amount if missing is the investor value, the correct value for stage is the old amount value and the investor value becomes NaN or missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows where 'investor' value is numeric using clean amount function\n",
    "mask = final_dataset[['investor', 'year']].apply(lambda row: pd.notna(clean_amount(row)), axis=1)\n",
    "\n",
    "# Update 'stage' column with the 'amount' value if stage is NaN\n",
    "stage_mask = final_dataset['stage'].isna()\n",
    "final_dataset.loc[mask & stage_mask, 'stage']    = final_dataset.loc[mask, 'amount']\n",
    "\n",
    "# Update 'amount' column with 'investor' value\n",
    "final_dataset.loc[mask, 'amount']                = final_dataset.loc[mask, 'investor']\n",
    "\n",
    "# Set 'investor' to NaN\n",
    "final_dataset.loc[mask, 'investor']              = np.nan\n",
    "         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the 'stage' value is a number or contains $, the column 'what_it does' becomes its old value concatenated with the value in the 'founder' column. The correct value for 'founder' is the 'investor' value and the correct value for 'investor' is the 'amount' value and correct 'amount' becomes the old 'stage' value while the correct value for 'stage' is NaN or missing. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows where 'stage' value is numeric using clean amount function\n",
    "mask = final_dataset[['stage', 'year']].apply(lambda row: pd.notna(clean_amount(row)), axis=1)\n",
    "\n",
    "# Update the 'what_it_does' column to its concatenation with 'founder' value\n",
    "old_what_it_does = final_dataset.loc[mask, 'what_it_does']\n",
    "old_founder      = final_dataset.loc[mask, 'founders']\n",
    "\n",
    "final_dataset.loc[mask, 'what_it_does']    = old_what_it_does.fillna('') + ' ' + old_founder.fillna('')\n",
    "\n",
    "# Update 'founder' column using the old 'investor' value\n",
    "final_dataset.loc[mask, 'founders']        = final_dataset.loc[mask, 'investor']\n",
    "\n",
    "# Update 'investor' column using the old 'amount' value\n",
    "final_dataset.loc[mask, 'investor']        = final_dataset.loc[mask, 'amount']\n",
    "\n",
    "# Update 'amount' column using the old 'stage' value\n",
    "final_dataset.loc[mask, 'amount']          = final_dataset.loc[mask, 'stage']\n",
    "\n",
    "# Set 'stage' to NaN\n",
    "final_dataset.loc[mask, 'stage']           = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean and convert amounts to USD and rename colume from amount to amount($)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and convert amounts to USD considering the average exchange rate per year\n",
    "final_dataset['amount'] = final_dataset[['amount','year']].apply(lambda row: clean_amount(row), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.rename(columns={'amount': 'amount($)'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the Headquarter Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix headquarter values, take every word before the first comma as headqurter\n",
    "def splitter(value):\n",
    "    \"\"\"\n",
    "    Splits a string by comma and returns the first part.\n",
    "\n",
    "    Args:\n",
    "        value (str or None): The value to be split.\n",
    "\n",
    "    Returns:\n",
    "        str or None: The first part of the string before the first comma, or the original value if the input is not a string.\n",
    "    \"\"\"\n",
    "    return value.split(',')[0] if isinstance(value, str) else value\n",
    "\n",
    "final_dataset['headquarter'] = [splitter(hq) for hq in final_dataset['headquarter']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Sector Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refactoring\n",
    "def heal_column_from_chars(df: pd.DataFrame, column: str = 'sector', chars: list = [',', ' ', '&', 'and', '/']) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a dataframe with the sector column having the least redundant value for sector.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to clean.\n",
    "        column (str): The name of the column to clean. Defaults to 'sector'.\n",
    "        chars (list): A list of characters or substrings to handle. Defaults to [',', ' ', '&', 'and', '/']. \n",
    "                      Always start with ',' because comma separated sector the most occuring multiple sector value.   \n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the specified column cleaned.\n",
    "    \"\"\"\n",
    "    \n",
    "    def count_char(value, char):\n",
    "        \"\"\"\n",
    "        Finds all occurrences of char in value and returns the count.\n",
    "        \n",
    "        Parameters:\n",
    "            value (str): The string in which to search for occurrences of char.\n",
    "            char (str): The character to count occurrences of.\n",
    "        \n",
    "        Returns:\n",
    "            int: The count of occurrences of char in value.\n",
    "        \"\"\"\n",
    "        # Use re.findall to find all occurrences of char in value and return the count\n",
    "        return len(re.findall(re.escape(char), str(value)))\n",
    "    \n",
    "    def char_to_nochar_value(char_value, char, no_char_column):\n",
    "        \"\"\"\n",
    "        Find the equivalent value of char_value in no_char_column.\n",
    "        \n",
    "        Parameters:\n",
    "            char_value (str): The string to process.\n",
    "            char (str): The character to split the char_value string.\n",
    "            no_char_column (pd.Series): The column containing unique values to search for the equivalent value.\n",
    "        \n",
    "        Returns:\n",
    "            str: The equivalent value found in no_char_column.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Default no char value        \n",
    "        no_char_value = char_value \n",
    "        \n",
    "        # Split by char, if char='and', \"Food and Beverage\" = [\"Food \", \" Beverage\"]\n",
    "        char_value    = char_value.split(char) \n",
    "        \n",
    "        # After, char_value is split, update no_char_value only if char is a comma\n",
    "        no_char_value = char_value[0] if char==',' else no_char_column\n",
    "        other_value = ''\n",
    "            \n",
    "        def find_index(where, value):\n",
    "            \"\"\"\n",
    "            Find the index where the given value matches the elements in the Series 'where'.\n",
    "            \n",
    "            Parameters:\n",
    "                where (pd.Series): The Series containing strings to search for the value.\n",
    "                value (str): The value to search for.\n",
    "            \n",
    "            Returns:\n",
    "                np.ndarray: The array of indices where the value matches in the Series.\n",
    "            \"\"\"\n",
    "            return np.where(where.str.lower().unique() == value.strip(char).lower())[0]\n",
    "            \n",
    "        for value in char_value: \n",
    "            other_value = other_value + char + value\n",
    "            # Find the index of value in unique no_char_column\n",
    "            indexof_value = find_index(where=no_char_column, value=value)\n",
    "            \n",
    "            # Find the index of other value in unique no_char_column\n",
    "            indexof_othervalue = find_index(where=no_char_column, value=other_value)\n",
    "            \n",
    "            if indexof_value.size == 1:\n",
    "                # If a unique match is found, update no_char_value\n",
    "                no_char_value = value              \n",
    "                break\n",
    "            elif indexof_othervalue.size == 1:  \n",
    "                # If a unique match is found, update no_char_value\n",
    "                no_char_value = other_value              \n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "        return no_char_value\n",
    "        \n",
    "    for char in chars: \n",
    "                \n",
    "        char_list = [count_char(value, char) for value in df[column]]\n",
    "                \n",
    "        char_threshold =  0\n",
    "\n",
    "        mask_char      = [x > char_threshold for x in char_list]    # Mask Boolean\n",
    "\n",
    "        mask_no_char   = [not x for x in mask_char]\n",
    "        \n",
    "        char_column    = df.loc[mask_char, column]\n",
    "\n",
    "        no_char_column = df.loc[mask_no_char, column]                \n",
    "\n",
    "        # Convert 'char' column to no 'char' column in the dataframe if there is a no 'char' equivalent    \n",
    "        df.loc[mask_char, column] = char_column.apply(lambda x: char_to_nochar_value(x, char, no_char_column))\n",
    "    \n",
    "    return df  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the sector column\n",
    "final_dataset = heal_column_from_chars(final_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sector- handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_sector(value):\n",
    "    \"\"\"\n",
    "    Fill missing sector values based on the content of 'what_it_does' column.\n",
    "\n",
    "    Parameters:\n",
    "    value (str): The content of the 'what_it_does' column.\n",
    "\n",
    "    Returns:\n",
    "    str: The assigned sector based on the content of 'what_it_does'.\n",
    "    \"\"\"\n",
    "    stopwords   = ['it', \"a\", \"an\", \"the\", \"and\", \"but\", \"or\"]  # Add other stopwords to exclude\n",
    "    \n",
    "    # Add more sectors and keywords\n",
    "    sector_keywords = {\n",
    "        'Technology': ['platform', 'platforms', 'platform.', 'applications', 'digital', 'digitizes'],\n",
    "        'Waste management': ['waste'],\n",
    "        'Skill development': ['skill, development'], \n",
    "        'Commerce': ['ecommerce'],\n",
    "        'Cosmetics':['skincare'],\n",
    "        'Rental': ['space'],\n",
    "        'HR': ['workforce'],\n",
    "        'Finance': ['financial'],\n",
    "        'Automobile': ['tyre'],\n",
    "        'EdTech': ['edutech']\n",
    "                        \n",
    "    }\n",
    "        \n",
    "    sector  = 'Others' # Default sector if no match is found\n",
    "    \n",
    "    sectors = final_dataset['sector']\n",
    "    \n",
    "    values  = [v for v in value.split(' ') if v.lower() not in stopwords]\n",
    "    \n",
    "    for v in values:\n",
    "         # Find the index of the sector in the sectors column\n",
    "        index_sector = np.where(sectors.str.lower().unique() == v.lower())[0] # Find the index of sector in unique sectors\n",
    "        \n",
    "        # If a match is found, assign the corresponding sector\n",
    "        if index_sector.size == 1:        \n",
    "            sector = sectors.unique()[index_sector[0]]              \n",
    "            break \n",
    "        # If no match is found, search for the word, v in the sector keywords dictionary and assign the corresponding sector \n",
    "        else:\n",
    "            sector = next((sector for sector, keywords in sector_keywords.items() if v.lower() in keywords), sector)\n",
    "    \n",
    "    return sector\n",
    "\n",
    "mask = final_dataset['sector'].isna()\n",
    "\n",
    "final_dataset.loc[mask, 'sector'] = final_dataset.loc[mask, 'what_it_does'].apply(fill_missing_sector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace falsely unique values or actual duplicates in categorical and string columns with their first occurence in the final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristic Function to replace actual duplicates with first occurrence\n",
    "def replace_col_duplicates(column):\n",
    "    \"\"\"\n",
    "        Replaces duplicates values (identified through some heuristics) in a column with their first occurrence \n",
    "        Although the first occurrence might not be the best representation but it allows for consistency in values\n",
    "        \n",
    "        Parameter: column\n",
    "        Returns  : column with consistent representation of values\n",
    "    \n",
    "    \"\"\"\n",
    "    actual_strings = {}  # Dictionary to store the first occurrence of each modified string\n",
    "    \n",
    "    def replace_string(string):\n",
    "        actual_string = re.sub(r'[^\\w]', '', string).lower() if isinstance(string, str) else string   # Replace all special characters including whitespaces with '' \n",
    "        if actual_string in actual_strings:\n",
    "            return actual_strings[actual_string]\n",
    "        else:\n",
    "            actual_strings[actual_string] = string\n",
    "            return string\n",
    "    return column.apply(replace_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['company_brand', 'headquarter', 'sector', 'founders', 'investor', 'stage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_values(columns):\n",
    "    for col in columns:\n",
    "        # Print count of unique items in columns of interest\n",
    "        print(f'{col}: {len(final_dataset[col].unique())}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of unique values before running replace_col_duplicates function\n",
    "count_unique_values(columns_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the replace actual duplicates function to the string or categorical columns\n",
    "for col in columns_of_interest:\n",
    "    final_dataset[col] = replace_col_duplicates(final_dataset[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of unique values after running replace_col_duplicates function\n",
    "count_unique_values(columns_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of missing values in the columns of final dataset\n",
    "final_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop duplicated rows in final data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicated from final dataset\n",
    "final_dataset.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, check the number of missing values in the columns of final dataset\n",
    "final_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change each column (founded and year) to appropriate Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Founded is year and datatype should be integer 32 handling missing values gracefuly\n",
    "final_dataset['founded'] = final_dataset['founded'].astype('Int32') # Int32 instead of int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year does not need to be int64 but int32\n",
    "final_dataset['year'] = final_dataset['year'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle missing values in the columns of the final dataset except company_brand, what_it_does and year which have no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Founded column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset['founded'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values in 'founded' column with median by year\n",
    "founded_median_by_year = final_dataset['founded']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headquarter column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sector column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Founders column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investor column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amount column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset['stage'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing values and replace Undisclosed values in 'stage' column with 'Venture - Series Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in 'stage' column with 'Venture - Series Unknown\n",
    "final_dataset['stage'].fillna('Venture - Series Unknown', inplace=True)\n",
    "\n",
    "# Replace Undisclosed values in 'stage' column with 'Venture - Series Unknown\n",
    "final_dataset['stage'].replace(to_replace='Undisclosed', value='Venture - Series Unknown', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset['stage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values in the Founders Column\n",
    "### The dataset had 545 missing values for the founders, so we decided to drop the column for founders as we will not need it for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.drop('founders', axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values in the Sector column\n",
    "### The sector column had 18 missing values so we filled them with the value Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset['sector'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the missing values in sector column with Unkownn\n",
    "final_dataset['sector'].fillna(\"Unknown\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(re.sub(r'[^\\,]', '', \"ar345547686,,4,5,,\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing values in the Investor Column\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mode for each sector in the 'investor' column\n",
    "mode_per_sector = final_dataset.groupby('sector')['investor'].transform(lambda x: x.mode().iloc[0] if not x.mode().empty else \"Unknown\")\n",
    "\n",
    "\n",
    "# Fill missing values in the 'investor' column with the calculated mode per sector\n",
    "final_dataset['investor'].fillna(mode_per_sector, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling null values in the column for Head Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "np.random.seed(2024)\n",
    "\n",
    "# Identify the rows with missing 'headquarter' values\n",
    "mask = final_dataset['headquarter'].isna()\n",
    "\n",
    "# Get non-missing values for final_dataset['headquarter']\n",
    "non_missing_hq = final_dataset.loc[mask==False, 'headquarter'] \n",
    "\n",
    "hq_missing     = mask.sum()\n",
    "\n",
    "# Randomly sample non-missing values to fill missing values of size hq_missing, 114\n",
    "hq_random      = np.random.choice(non_missing_hq, size=hq_missing)\n",
    "\n",
    "# Fill missing values with randomly sampled headquarter values\n",
    "final_dataset.loc[mask, 'headquarter'] = hq_random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling Null Values in Founded Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median founded grouped by year values\n",
    "founded_median_per_year = final_dataset.groupby('year')['founded'].median()\n",
    "\n",
    "# Calculate the overall median of median_per_year\n",
    "overall_median_per_year = founded_median_per_year.median()\n",
    "\n",
    "# Fill NaN values in founded_median_per_year with the overall median of median_per_year\n",
    "founded_median_per_year.fillna(overall_median_per_year, inplace=True)\n",
    "\n",
    "# Fill missing values in the 'founded' column with the calculated median per year\n",
    "final_dataset['founded'].fillna(final_dataset['year'].map(founded_median_per_year), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling Null Values in the Amount column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_median = final_dataset['amount($)'].median()\n",
    "final_dataset['amount($)'].fillna(amount_median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save datasets as flat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset from Microsoft SQL database\n",
    "# first_dataset.to_csv('DataSets/individual_csv/startup_funding2020-2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final merged dataset with cleaned column names and cleaned amount values\n",
    "# final_dataset.to_csv('DataSets/final_csv/startup_funding2018-2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startups_in_bangalore = final_dataset[final_dataset['headquarter']=='Bangalore']\n",
    "startups_not_in_bangalore = final_dataset[final_dataset['headquarter']!='Bangalore']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mann-Whitney U test: amount($) values are not normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Mann-Whitney U test\n",
    "t, p = mannwhitneyu(startups_in_bangalore['amount($)'],startups_not_in_bangalore['amount($)'], alternative='two-sided')\n",
    "\n",
    "# Print the test statistic and p-value\n",
    "print(\"Mann-Whitney U test statistic:\", t)\n",
    "print(\"P-value:\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Significance level\n",
    "alpha = 0.05\n",
    "\n",
    "#Compare p-value to the significance level\n",
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis. Which is there is no siginificate difference in the amount of funding between startups in Bangalore.\")\n",
    "else:\n",
    "   print(\"We failed to reject the null hypothesis. There is a siginificate difference in the amount of funding between startups in Bangalore.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_dataset['headquarter'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset['stage'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What sectors have shown the highest growth in terms of funding received over the past four years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_sector_2018 = final_dataset[final_dataset['year']==2018]\n",
    "year_sector_2019 = final_dataset[final_dataset['year']==2019]\n",
    "year_sector_2020 = final_dataset[final_dataset['year']==2020]\n",
    "year_sector_2021 = final_dataset[final_dataset['year']==2021]\n",
    "\n",
    "\n",
    "#Group 2018 data by sector and get the sum of the amount\n",
    "sector_year_funding_2018 = year_sector_2018.groupby('sector')['amount($)'].sum()/ 1e9\n",
    "sector_year_funding_2018_reset = sector_year_funding_2018.reset_index().sort_values(by='amount($)', ascending=False).head(5)\n",
    "\n",
    "#Group 2019 data by sector and get the sum of the amount\n",
    "sector_year_funding_2019 = year_sector_2019.groupby('sector')['amount($)'].sum()/ 1e9\n",
    "sector_year_funding_2019_reset = sector_year_funding_2019.reset_index().sort_values(by='amount($)', ascending=False).head(5)\n",
    "\n",
    "#Group 2020 data by sector and get the sum of the amount\n",
    "sector_year_funding_2020 = year_sector_2020.groupby('sector')['amount($)'].sum()/ 1e9\n",
    "sector_year_funding_2020_reset = sector_year_funding_2020.reset_index().sort_values(by='amount($)', ascending=False).head(5)\n",
    "\n",
    "#Group 2021 data by sector and get the sum of the amount\n",
    "sector_year_funding_2021 = year_sector_2021.groupby('sector')['amount($)'].sum()/ 1e9\n",
    "sector_year_funding_2021_reset = sector_year_funding_2021.reset_index().sort_values(by='amount($)', ascending=False).head(5)\n",
    "\n",
    "sector_year_funding_2018_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(16, 9))\n",
    "\n",
    "# Function to annotate each bar with the amount\n",
    "def annotate_bars(data, ax):\n",
    "    for index, value in enumerate(data['amount($)']):\n",
    "        ax.text(value, index, f'{value:.2f}B', ha='left', va='center', fontsize=10)\n",
    "\n",
    "# Plotting for 2018\n",
    "sns.barplot(x='amount($)', y='sector', data=sector_year_funding_2018_reset, palette=\"viridis\", ax=axes[0, 0])\n",
    "annotate_bars(sector_year_funding_2018_reset, axes[0, 0])\n",
    "axes[0, 0].set_title('Top 5 Sectors with Highest Growth in Funding in 2018')\n",
    "axes[0, 0].set_xlabel('Average Growth in Funding (In Billions)')\n",
    "axes[0, 0].set_ylabel('Top 5 Sectors in 2018')\n",
    "\n",
    "# Plotting for 2019\n",
    "sns.barplot(x='amount($)', y='sector', data=sector_year_funding_2019_reset, palette=\"viridis\", ax=axes[0, 1])\n",
    "annotate_bars(sector_year_funding_2019_reset, axes[0, 1])\n",
    "axes[0, 1].set_title('Top 5 Sectors with Highest Growth in Funding in 2019')\n",
    "axes[0, 1].set_xlabel('Average Growth in Funding (In Billions)')\n",
    "axes[0, 1].set_ylabel('Top 5 Sectors in 2019')\n",
    "\n",
    "# Plotting for 2020\n",
    "sns.barplot(x='amount($)', y='sector', data=sector_year_funding_2020_reset, palette=\"viridis\", ax=axes[1, 0])\n",
    "annotate_bars(sector_year_funding_2020_reset, axes[1, 0])\n",
    "axes[1, 0].set_title('Top 5 Sectors with Highest Growth in Funding in 2020')\n",
    "axes[1, 0].set_xlabel('Average Growth in Funding (In Billions)')\n",
    "axes[1, 0].set_ylabel('Top 5 Sectors in 2020')\n",
    "\n",
    "# Plotting for 2021\n",
    "sns.barplot(x='amount($)', y='sector', data=sector_year_funding_2021_reset, palette=\"viridis\", ax=axes[1, 1])\n",
    "annotate_bars(sector_year_funding_2021_reset, axes[1, 1])\n",
    "axes[1, 1].set_title('Top 5 Sectors with Highest Growth in Funding in 2021')\n",
    "axes[1, 1].set_xlabel('Average Growth in Funding (In Billions)')\n",
    "axes[1, 1].set_ylabel('Top 5 Sectors in 2021')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Convert the 'growth' values to billions\n",
    "# sector_year_funding_2018_reset['growth_billions'] = sector_year_funding_2018_reset['amount($)'] / 1e9\n",
    "\n",
    "# # Plotting using seaborn\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# bar_plot = sns.barplot(x='growth_billions', y='sector', data=sector_year_funding_2018_reset, palette=\"viridis\")\n",
    "\n",
    "# plt.title('Top 5 Sectors with Highest Growth in Funding in 2018')\n",
    "# plt.xlabel('Average Growth in Funding (In Billions)')\n",
    "# plt.ylabel('Top 5 Sectors in 2018')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Convert the 'growth' values to billions\n",
    "# sector_year_funding_2019_reset['growth_billions'] = sector_year_funding_2019_reset['amount($)'] / 1e9\n",
    "\n",
    "# # Plotting using seaborn\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# bar_plot = sns.barplot(x='growth_billions', y='sector', data=sector_year_funding_2019_reset, palette=\"viridis\")\n",
    "\n",
    "\n",
    "# plt.title('Top 5 Sectors with Highest Growth in Funding in 2019')\n",
    "# plt.xlabel('Average Growth in Funding (In Billions)')\n",
    "# plt.ylabel('Top 5 Sectors in 2019')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Convert the 'growth' values to billions\n",
    "# sector_year_funding_2020_reset['growth_billions'] = sector_year_funding_2020_reset['amount($)'] / 1e9\n",
    "\n",
    "# # Plotting using seaborn\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# bar_plot = sns.barplot(x='growth_billions', y='sector', data=sector_year_funding_2020_reset, palette=\"viridis\")\n",
    "\n",
    "\n",
    "# plt.title('Top 5 Sectors with Highest Growth in Funding in 2020')\n",
    "# plt.xlabel('Average Growth in Funding (In Billions)')\n",
    "# plt.ylabel('Top 5 Sectors in 2020')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Convert the 'growth' values to billions\n",
    "# sector_year_funding_2021_reset['growth_billions'] = sector_year_funding_2021_reset['amount($)'] / 1e9\n",
    "\n",
    "# # Plotting using seaborn\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# bar_plot = sns.barplot(x='growth_billions', y='sector', data=sector_year_funding_2021_reset, palette=\"viridis\")\n",
    "\n",
    "\n",
    "# plt.title('Top 5 Sectors with Highest Growth in Funding in 2021')\n",
    "# plt.xlabel('Average Growth in Funding (In Billions)')\n",
    "# plt.ylabel('Top 5 Sectors in 2021')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What locations within India have emerged as the primary hubs for startup activity and investment, and what factors contribute to their prominence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grouping the dataset based on the headquarters\n",
    "# startups_by_location = final_dataset.groupby('headquarter')['amount($)'].sum()\n",
    "\n",
    "# #Reset index and get the top 10 locations\n",
    "# top_10_locations = startups_by_location.reset_index().sort_values(by ='amount($)', ascending = False).head(10)\n",
    "\n",
    "# # top_10_locations\n",
    "\n",
    "# # #Convert the 'growth' values to billions\n",
    "# top_10_locations['growth_billions'] = top_10_locations['amount($)'] / 1e9\n",
    "\n",
    "# # Plotting using seaborn\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# bar_plot = sns.barplot(x='growth_billions', y='headquarter', data=top_10_locations, palette=\"viridis\")\n",
    "# # Add the numbers near the bars\n",
    "# for i, v in enumerate(top_10_locations['growth_billions']):\n",
    "#     bar_plot.text(v + 3, i + .25, str(v), color='black', fontweight='light')\n",
    "\n",
    "# plt.title('Top 10 locations with the Highest Startup activity and Investment')\n",
    "# plt.xlabel('Average Investment in Funding (In Billions)')\n",
    "# plt.ylabel('Top 10 locations')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the dataset based on the headquarters\n",
    "startups_by_location = final_dataset.groupby('headquarter')['amount($)'].sum()\n",
    "# Reset the index before assigning column names\n",
    "top_10_locations_by_investment = startups_by_location.reset_index().sort_values(by ='amount($)', ascending = False).head(10)\n",
    "top_10_locations_by_investment['growth_billions'] = top_10_locations_by_investment['amount($)'] / 1e9\n",
    "\n",
    "# Assign column names\n",
    "top_10_locations_by_investment.columns = ['headquarter', 'amount($)', 'growth_billions']\n",
    "# top_10_locations_by_investment\n",
    "\n",
    "# Initialize the Nominatim geocoder\n",
    "geolocator = Nominatim(user_agent=\"my_geocoder\")\n",
    "\n",
    "# Function to retrieve coordinates for a location\n",
    "def get_coordinates(location):\n",
    "    try:\n",
    "        location_info = geolocator.geocode(location)\n",
    "        if location_info:\n",
    "            return location_info.latitude, location_info.longitude\n",
    "        else:\n",
    "            print(f\"Warning: Coordinates not found for {location}. Skipping.\")\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving coordinates for {location}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "# Apply the function to get coordinates for each location\n",
    "top_10_locations_by_investment[['Latitude', 'Longitude']] = top_10_locations_by_investment['headquarter'].apply(lambda x: pd.Series(get_coordinates(x)))\n",
    "top_10_locations_by_investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a map centered around the first location\n",
    "map_top_10_locations_by_investment= folium.Map(location=[top_10_locations_by_investment['Latitude'].iloc[0], top_10_locations_by_investment['Longitude'].iloc[0]], zoom_start=3)\n",
    "marker_cluster = MarkerCluster().add_to(map_top_10_locations_by_investment)\n",
    "\n",
    "# Add a marker for each location to the MarkerCluster\n",
    "for idx, row in top_10_locations_by_investment.iterrows():\n",
    "    radius = int(row['growth_billions'] / 1e9)\n",
    "    folium.Marker(\n",
    "        location=[row['Latitude'], row['Longitude']],\n",
    "        popup=folium.Popup(('<strong><font color =\"green\">'+row['headquarter']+'</font></strong><br>'+\n",
    "                            '<strong>Total Investment (Billions): </strong><font color =\"blue\">'+str(row['growth_billions'])+'</font><br>'), max_width=250),\n",
    "    ).add_to(marker_cluster)\n",
    "map_top_10_locations_by_investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# startups_by_location2 = final_dataset['headquarter'].value_counts()\n",
    "\n",
    "# # Reset index and get the top 10 locations\n",
    "# top_10_locations2 = startups_by_location2.head(10).sort_values(ascending=False).reset_index()\n",
    "# top_10_locations2.columns = ['headquarter', 'count']\n",
    "\n",
    "\n",
    "# # Plotting using seaborn\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# ax = sns.barplot(x='count', y='headquarter', data=top_10_locations2, palette=\"viridis\")\n",
    "\n",
    "# # Add the numbers near the bars\n",
    "# for i, v in enumerate(top_10_locations2['count']):\n",
    "#     ax.text(v + 3, i + .25, str(v), color='black', fontweight='light')\n",
    "\n",
    "# plt.title('Top 10 locations with the Highest Startups')\n",
    "# plt.xlabel('Number of Startups')\n",
    "# plt.ylabel('Top 10 locations')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startups_by_location2 = final_dataset['headquarter'].value_counts()\n",
    "top_10_locations = startups_by_location2.head(10).sort_values(ascending=False).reset_index()\n",
    "top_10_locations.columns = ['Location', 'Number of Startups']\n",
    "\n",
    "# Initialize the Nominatim geocoder\n",
    "geolocator = Nominatim(user_agent=\"my_geocoder\")\n",
    "\n",
    "# Function to retrieve coordinates for a location\n",
    "def get_coordinates(location):\n",
    "    try:\n",
    "        location_info = geolocator.geocode(location)\n",
    "        if location_info:\n",
    "            return location_info.latitude, location_info.longitude\n",
    "        else:\n",
    "            print(f\"Error retrieving coordinates for {location}: Location not found\")\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving coordinates for {location}: {str(e)}\")\n",
    "        return None, None\n",
    "# Apply the function to get coordinates for each location\n",
    "top_10_locations[['Latitude', 'Longitude']] = top_10_locations['Location'].apply(lambda x: pd.Series(get_coordinates(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map centered around the first location\n",
    "map_top_10_locations = folium.Map(location=[top_10_locations['Latitude'].iloc[0], top_10_locations['Longitude'].iloc[0]], zoom_start=3)\n",
    "\n",
    "# Create a MarkerCluster to cluster the markers\n",
    "marker_cluster = MarkerCluster().add_to(map_top_10_locations)\n",
    "\n",
    "# Add a marker for each location to the MarkerCluster\n",
    "for idx, row in top_10_locations.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row['Latitude'], row['Longitude']],\n",
    "        popup=folium.Popup(('<strong><font color =\"green\">'+row['Location']+'</font></strong><br>'+\n",
    "                            '<strong>Number of Startups: </strong><font color =\"blue\">'+str(row['Number of Startups'])+'</font><br>'), max_width=250),\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "# Display the map\n",
    "map_top_10_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Grouping the dataset based on the headquarters\n",
    "# startups_by_location2 = final_dataset['headquarter'].value_counts()\n",
    "\n",
    "# #Reset index and get the top 10 locations\n",
    "# top_10_locations2 = startups_by_location2.head(10).sort_values(ascending = False).reset_index()\n",
    "\n",
    "\n",
    "# # Plotting using seaborn\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# ax = sns.barplot(x='count', y='headquarter', data=top_10_locations2, palette=\"viridis\")\n",
    "\n",
    "# plt.title('Top 10 locations with the Highest Startups')\n",
    "# plt.xlabel('Number of Startups')\n",
    "# plt.ylabel('Top 10 locations')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there any notable differences in funding patterns between early-stage startups and more established companies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the median year for the founded coulmn\n",
    "overall_median_per_year  # The overall median year is 2016\n",
    "\n",
    "final_dataset['stage_of_startup'] = np.where(final_dataset['founded'] >= overall_median_per_year, 'Early Stage', 'Established')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the count of each category in the 'stage' column\n",
    "stage_distribution = final_dataset['stage_of_startup'].value_counts()\n",
    "\n",
    "# Print or visualize the distribution\n",
    "print(stage_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot countplot for 'stage'\n",
    "sns.countplot(x='stage_of_startup', data=final_dataset, ax=ax, palette=\"viridis\")\n",
    "\n",
    "# Display the count above each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "\n",
    "plt.title('Distribution of Companies by Stage')\n",
    "plt.xlabel('Stage')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stage_stats = final_dataset[final_dataset['stage_of_startup'] == 'Early Stage']['amount($)'].describe()\n",
    "established_stats = final_dataset[final_dataset['stage_of_startup'] == 'Established']['amount($)'].describe()\n",
    "\n",
    "print(\"Early Stage Funding Statistics:\")\n",
    "print(early_stage_stats)\n",
    "\n",
    "print(\"\\nEstablished Funding Statistics:\")\n",
    "print(established_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####\n",
    "**Mean Funding Amount:** Early-stage companies have a slightly lower mean funding amount ($83.88 million) compared to established companies ($136.97 million).\n",
    "\n",
    "**Variability (Standard Deviation):** Both groups exhibit high variability in funding amounts, as indicated by the large standard deviations.\n",
    "\n",
    "**Minimum and Maximum Funding:** Both groups have a wide range of funding amounts, with early-stage companies having a minimum of $720 and a maximum of $150 billion, while established companies range from $40,900 to $70 billion.\n",
    "\n",
    "**Percentiles (Q1, Median, Q3):** Early-stage companies generally have lower funding amounts at each percentile compared to established companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stage_startups = final_dataset.groupby('stage_of_startup')['amount($)'].sum().reset_index()\n",
    "early_stage_startups['amount_in_billions'] = early_stage_startups['amount($)'] / 1e9\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x='stage_of_startup', y='amount_in_billions', data=early_stage_startups, ci=None, palette=\"viridis\")\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height():.2f}B', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "\n",
    "plt.title('Comparison of Funding Amounts between Early Stage and Established Companies')\n",
    "plt.xlabel('Stage')\n",
    "plt.ylabel('Amount ($B)')\n",
    "plt.show()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis Testing\n",
    "\n",
    "#### \n",
    "Null Hypothesis(H0): There is no significant difference in the average funding amounts between early-stage startups and established companies.\n",
    "\n",
    "Alternative Hypothesis(H1): There is a significant difference in the average funding amounts between early-stage startups and established companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stage_funding = final_dataset[final_dataset['stage_of_startup'] == 'Early Stage']['amount($)']\n",
    "established_funding = final_dataset[final_dataset['stage_of_startup'] == 'Established']['amount($)']\n",
    "\n",
    "t_stat, p_value = ttest_ind(early_stage_funding, established_funding, nan_policy='omit')\n",
    "\n",
    "\n",
    "# Set Significance level\n",
    "alpha = 0.05\n",
    " \n",
    "#Compare p-value to the significance level\n",
    "if p_value < alpha:\n",
    "    print('We reject the Null hypothesis.There is no significant difference in the average funding amounts between early_stage startups and established companies')\n",
    "else:\n",
    "   print(\"We fail to reject the Null hypothesis\")\n",
    "\n",
    "\n",
    "# print(f\"T-statistic: {t_stat}\")\n",
    "# print(f\"P-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for numerical columns\n",
    "numerical_summary = final_dataset.describe()\n",
    "\n",
    "# Create a figure with subplots for each numerical column\n",
    "fig = make_subplots(rows=1, cols=len(numerical_summary.columns) - 1, subplot_titles=numerical_summary.columns[1:])\n",
    "\n",
    "# Iterate over numerical columns and add histograms to subplots\n",
    "for i, column in enumerate(numerical_summary.columns[1:], start=1):  # Start from the second column\n",
    "    fig.add_trace(go.Histogram(x=final_dataset[column], nbinsx=20, name=column), row=1, col=i)\n",
    "\n",
    "# Update the layout\n",
    "fig.update_layout(title='Distribution of Numerical Columns',\n",
    "                  xaxis_title='Value',\n",
    "                  yaxis_title='Frequency',\n",
    "                  height=400,  # Set the height of the figure\n",
    "                  width=900)  # Set the width of the figure\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a count plot for Sector using Plotly Express\n",
    "fig = px.histogram(final_dataset, x='sector', title='Count of Startups in Each Sector')\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(xaxis_title='Sector', yaxis_title='Count', barmode='group',height =400, width = 800)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical-Numerical relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot using Plotly Express\n",
    "fig = px.scatter(final_dataset, x='year', y='amount($)', title='Amount($) vs. Funding Year',\n",
    "                 labels={'year': 'Funding Year', 'amount($)': 'Amount($)'})\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(xaxis_title='Funding Year', yaxis_title='Amount($)', xaxis_tickangle=-45, height =400, width = 800)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical-Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the box plot using Plotly Express\n",
    "fig = px.box(final_dataset, x='sector', y='amount($)', title='Amount($) Distribution Across Sectors',\n",
    "             labels={'sector': 'Sector', 'amount($)': 'Amount($)'})\n",
    "fig.update_layout(xaxis={'categoryorder': 'total descending'},\n",
    "                  height=400,\n",
    "                  width=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change to question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Calculate average funding received by each sector per year\n",
    "average_per_year = final_dataset.groupby(['year', 'sector'])['amount($)'].sum().reset_index()\n",
    "\n",
    "# Get top 5 sectors by average funding received\n",
    "top_5_sectors = average_per_year.groupby('sector')['amount($)'].sum().nlargest(5).index\n",
    "\n",
    "# Filter the data for only the top 5 sectors\n",
    "average_per_year_top5 = average_per_year[average_per_year['sector'].isin(top_5_sectors)]\n",
    "\n",
    "# Pivot the table to have sectors as rows and years as columns\n",
    "pivot_table = average_per_year_top5.pivot(index='year', columns='sector', values='amount($)')\n",
    "\n",
    "# Divide the amount by 1 billion to convert to billions\n",
    "pivot_table_in_billions = pivot_table / 1e9\n",
    "\n",
    "# Plot the average funding received for each sector over the years (line plot) in billions\n",
    "ax = pivot_table_in_billions.plot(kind='line', figsize=(12, 6))\n",
    "\n",
    "# Set a custom formatter to display \"B\" for billions on the y-axis\n",
    "def billions_formatter(x, pos):\n",
    "    return f'{x:.0f}B'\n",
    "\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(billions_formatter))\n",
    "\n",
    "plt.title('Average Funding Received by Top 5 Sectors (2018-2021)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Average Funding Received (Billions)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Sector')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which sectors recieve the lowest level of funding and which sectors recieve the highest levels of funding in India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by sector and get the sum of the amount\n",
    "sector_year_funding = final_dataset.groupby('sector')['amount($)'].sum()\n",
    "sector_year_funding_reset = sector_year_funding.reset_index().sort_values(by='amount($)', ascending=False).head(5)\n",
    "\n",
    "# Convert the 'growth' values to billions\n",
    "sector_year_funding_reset['growth_billions'] = sector_year_funding_reset['amount($)'] / 1e9\n",
    "\n",
    "def annotate_bars(data, ax):\n",
    "    for index, value in enumerate(data['growth_billions']):\n",
    "        ax.text(value, index, f'{value:.2f}B', ha='left', va='center', fontsize=10)\n",
    "\n",
    "# Plotting using seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x='growth_billions', y='sector', data=sector_year_funding_reset, palette=\"viridis\")\n",
    "\n",
    "plt.title('Top 5 Sectors with Highest Growth in Funding')\n",
    "plt.xlabel('Average Growth in Funding (In Billions)')\n",
    "plt.ylabel('Top 5 Sectors')\n",
    "\n",
    "# Annotate the bars with values\n",
    "annotate_bars(sector_year_funding_reset, ax)\n",
    "plt.show()\n",
    "sector_year_funding_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group data by sector and get the sum of the amount\n",
    "sector_year_funding = final_dataset.groupby('sector')['amount($)'].sum()\n",
    "sector_year_funding_reset = sector_year_funding.reset_index().sort_values(by='amount($)', ascending=False).tail(5)\n",
    "\n",
    "#Convert the 'growth' values to billions\n",
    "# sector_year_funding_reset['growth_billions'] = sector_year_funding_reset['amount($)'] / 1e9\n",
    "\n",
    "def annotate_bars(data, ax):\n",
    "    for index, value in enumerate(data['amount($)']):\n",
    "        ax.text(value, index, f'{value:.2f}', ha='left', va='center', fontsize=10)\n",
    "\n",
    "# Plotting using seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x='amount($)', y='sector', data=sector_year_funding_reset, palette=\"viridis\")\n",
    "\n",
    "annotate_bars(sector_year_funding_reset,ax)\n",
    "plt.title('Least 5 Sectors with Lowest Growth in Funding')\n",
    "plt.xlabel('Average Growth in Funding (In Thousands)')\n",
    "plt.ylabel('Least 5 Sectors')\n",
    "plt.show()\n",
    "sector_year_funding_reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which investors have more impact on startups over the years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by investor and sum the investment amounts\n",
    "investor_impact = final_dataset.groupby('investor')['amount($)'].sum()\n",
    "\n",
    "# Get the top 10 investors with the highest total investment amounts\n",
    "top_10_investors = investor_impact.nlargest(10)\n",
    "\n",
    "#Return top 10 investors\n",
    "top_10_investors\n",
    "\n",
    "# Reset index and rename the columns\n",
    "top_10_investors_reset = top_10_investors.reset_index()\n",
    "top_10_investors_reset.columns = ['Investor', 'amount']\n",
    "top_10_investors_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'amount' values to billions\n",
    "top_10_investors_reset['amount_billions'] = top_10_investors_reset['amount'] / 1e9\n",
    "\n",
    "# Sort the DataFrame by 'amount_billions' column in descending order\n",
    "top_10_investors_reset = top_10_investors_reset.sort_values(by='amount_billions', ascending=False)\n",
    "\n",
    "# Plotting using seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "bar_plot = sns.barplot(x='amount_billions', y='Investor', data=top_10_investors_reset, palette=\"viridis\")\n",
    "\n",
    "# Add data labels\n",
    "for index, row in top_10_investors_reset.iterrows():\n",
    "    bar_plot.text(row['amount_billions'], index, f'{row[\"amount_billions\"]:.2f}B', va='center')\n",
    "\n",
    "plt.title('Top 10 Investors Impact on Startups Over the Years')\n",
    "plt.xlabel('Total Investment Amount (Billions $)')\n",
    "plt.ylabel('Investor')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "In the Indian ecosystem, Venture Catalysts emerges as the top investor with the highest amount of investments, closely followed by Silver Lake. This reflects the diverse and dynamic investment landscape in India, showcasing both local players like Venture Catalysts and global investors like Silver Lake actively participating and contributing to the growth of startups and businesses in the country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations\n",
    "Based on the analysis of funding trends from 2018 to 2021, the Technology sector emerges as a top performer, attracting significant investments and showcasing remarkable growth. This sector presents lucrative opportunities for investors and entrepreneurs alike, particularly in areas such as software development, artificial intelligence, e-commerce, and digital services. Therefore, it is highly recommended to explore investment avenues within the Technology sector due to its potential for favorable returns and innovation-driven growth.\n",
    "\n",
    "Additionally, diversifying investment portfolios to include sectors that integrate technology, such as retail and healthcare, can further enhance investment prospects. Tech-enabled solutions in these sectors have demonstrated promising potential and are likely to attract increased funding.\n",
    "\n",
    "Furthermore, considering the strong correlation between amount of funding and location, setting up startups in technology-focused hubs like Bangalore can expedite access to finance and support ecosystem collaborations. Mumbai, with its thriving startup ecosystem and substantial funding activity, also presents compelling opportunities for networking and investment exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "Based on the analysis of funding trends from 2018 to 2021, it's evident that the Technology sector has been a standout performer, attracting significant investments. This sector, along with related tech-incorporated sectors like retail and health, presents promising opportunities for investors and entrepreneurs. Bangalore and Mumbai, being a prominent hub for startups and investments, offers valuable networking prospects. Therefore, exploring opportunities in tech-driven sectors and engaging with Mumbai's startup ecosystem could lead to favorable outcomes in terms of growth and innovation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made with ðŸ’– [Team Curium](https://github.com/MumoMutiso/Indian-startup-collab)\n",
    "<span style=\"color: #aaaaaa;\">2024</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
